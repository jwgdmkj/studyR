{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCNko8tq0D2vWdTx4K+cZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwgdmkj/HelloGitHub/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UKc-H1ydf8_a",
        "outputId": "ac65a445-3634-4504-8036-8179f6de4a51"
      },
      "source": [
        "#linear regression: x y 데이터의 상관관계를 linear한 모델로 하는 것\n",
        "#최적화된 빨간 선을, keras로 구현\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "bpIM0x0ugNXM",
        "cellView": "form",
        "collapsed": true,
        "outputId": "5cb552d9-ab49-41c7-9a39-5659550cf569"
      },
      "source": [
        "#@title\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path\n",
        "\n",
        "# 받은 데이터는 csv형태로 저장됨.\n",
        "# pandas 형태로 csv파일을 읽음\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail() #dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  ...  Acceleration  Model Year  Origin\n",
              "393  27.0          4         140.0  ...          15.6          82       1\n",
              "394  44.0          4          97.0  ...          24.6          82       2\n",
              "395  32.0          4         135.0  ...          11.6          82       1\n",
              "396  28.0          4         120.0  ...          18.6          82       1\n",
              "397  31.0          4         119.0  ...          19.4          82       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XNOCajFCLil",
        "outputId": "44e3cfea-97d7-494d-c1fe-08a5bac969e9"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unx4f30oDAlZ",
        "outputId": "4ee231f8-ceba-4ea0-cb29-668259d6198a"
      },
      "source": [
        "#dataset.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPG             0\n",
              "Cylinders       0\n",
              "Displacement    0\n",
              "Horsepower      0\n",
              "Weight          0\n",
              "Acceleration    0\n",
              "Model Year      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv6y-W2Wkpnb"
      },
      "source": [
        "# len(dataset) #398개의 데이터가 준비됨\n",
        "# origin : 국가의 분류. 이는 필요하지 않은 data 이므로, 제거\n",
        "dataset.pop('Origin') \n",
        "\n",
        "#training set과 test_set을 분류 (overfitting 방지)\n",
        "train_dataset = dataset.sample(frac = 0.8, random_state = 0) #80%만 train에 사용\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPIr86OTE67Z",
        "outputId": "41b2f62b-22cd-41ca-b436-5ee940501283"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(318, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "oQyP0oW8vTtX",
        "outputId": "a6a3e4b8-5b77-4348-ace3-f8f3333f370a"
      },
      "source": [
        "#모델 설계에 앞서, 데이터 정규화를 통해 편차를 감소시켜야 함\n",
        "#이때, MPG라는 값은 정규화가 불필요하기에, 새로운 '레이블'이란 이름으로 정의\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop('MPG')\n",
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cylinders</th>\n",
              "      <td>314.0</td>\n",
              "      <td>5.477707</td>\n",
              "      <td>1.699788</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Displacement</th>\n",
              "      <td>314.0</td>\n",
              "      <td>195.318471</td>\n",
              "      <td>104.331589</td>\n",
              "      <td>68.0</td>\n",
              "      <td>105.50</td>\n",
              "      <td>151.0</td>\n",
              "      <td>265.75</td>\n",
              "      <td>455.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horsepower</th>\n",
              "      <td>314.0</td>\n",
              "      <td>104.869427</td>\n",
              "      <td>38.096214</td>\n",
              "      <td>46.0</td>\n",
              "      <td>76.25</td>\n",
              "      <td>94.5</td>\n",
              "      <td>128.00</td>\n",
              "      <td>225.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>314.0</td>\n",
              "      <td>2990.251592</td>\n",
              "      <td>843.898596</td>\n",
              "      <td>1649.0</td>\n",
              "      <td>2256.50</td>\n",
              "      <td>2822.5</td>\n",
              "      <td>3608.00</td>\n",
              "      <td>5140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acceleration</th>\n",
              "      <td>314.0</td>\n",
              "      <td>15.559236</td>\n",
              "      <td>2.789230</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.80</td>\n",
              "      <td>15.5</td>\n",
              "      <td>17.20</td>\n",
              "      <td>24.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Year</th>\n",
              "      <td>314.0</td>\n",
              "      <td>75.898089</td>\n",
              "      <td>3.675642</td>\n",
              "      <td>70.0</td>\n",
              "      <td>73.00</td>\n",
              "      <td>76.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              count         mean         std  ...     50%      75%     max\n",
              "Cylinders     314.0     5.477707    1.699788  ...     4.0     8.00     8.0\n",
              "Displacement  314.0   195.318471  104.331589  ...   151.0   265.75   455.0\n",
              "Horsepower    314.0   104.869427   38.096214  ...    94.5   128.00   225.0\n",
              "Weight        314.0  2990.251592  843.898596  ...  2822.5  3608.00  5140.0\n",
              "Acceleration  314.0    15.559236    2.789230  ...    15.5    17.20    24.8\n",
              "Model Year    314.0    75.898089    3.675642  ...    76.0    79.00    82.0\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "0rO5uN63wI5k",
        "outputId": "cbd9e322-8d86-4838-b577-68ce46f03941"
      },
      "source": [
        "def norm(x):\n",
        "  return(x- train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "\n",
        "#x데이터 준비 완료. 여기에, linear 모델(x*행렬 w+bias 가 y값을 의미)\n",
        "#이 input data와 곱해질 행렬값을 학습하게 됨\n",
        "normed_train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>-0.869348</td>\n",
              "      <td>-1.009459</td>\n",
              "      <td>-0.784052</td>\n",
              "      <td>-1.025303</td>\n",
              "      <td>-0.379759</td>\n",
              "      <td>-0.516397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>-0.869348</td>\n",
              "      <td>-0.530218</td>\n",
              "      <td>-0.442811</td>\n",
              "      <td>-0.118796</td>\n",
              "      <td>0.624102</td>\n",
              "      <td>0.843910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1.483887</td>\n",
              "      <td>1.482595</td>\n",
              "      <td>1.447140</td>\n",
              "      <td>1.736877</td>\n",
              "      <td>-0.738281</td>\n",
              "      <td>-1.060519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>-0.869348</td>\n",
              "      <td>-0.865687</td>\n",
              "      <td>-1.099044</td>\n",
              "      <td>-1.025303</td>\n",
              "      <td>-0.308055</td>\n",
              "      <td>1.660094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>-0.869348</td>\n",
              "      <td>-0.942365</td>\n",
              "      <td>-0.994047</td>\n",
              "      <td>-1.001603</td>\n",
              "      <td>0.875068</td>\n",
              "      <td>1.115971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cylinders  Displacement  Horsepower    Weight  Acceleration  Model Year\n",
              "146  -0.869348     -1.009459   -0.784052 -1.025303     -0.379759   -0.516397\n",
              "282  -0.869348     -0.530218   -0.442811 -0.118796      0.624102    0.843910\n",
              "69    1.483887      1.482595    1.447140  1.736877     -0.738281   -1.060519\n",
              "378  -0.869348     -0.865687   -1.099044 -1.025303     -0.308055    1.660094\n",
              "331  -0.869348     -0.942365   -0.994047 -1.001603      0.875068    1.115971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1mrQJ1hxDMp"
      },
      "source": [
        "# 그 행렬 모델을 만든다\n",
        "# keras 모델이 알아야 할 것: input shape\n",
        "# 318, 6: 현재 data 수와, 칼럼의 수. 이 중 칼럼을 중시한다.\n",
        "normed_train_data.shape\n",
        "inputs = keras.Input(shape=(normed_train_data.shape[1],)) # 6을 shape에 대입\n",
        "\n",
        "# 행렬 만들기.\n",
        "h= layers.Dense(64)(inputs) #64짜리 feature의 행렬 생성. \n",
        "# 최종 행렬은, y가 숫자 MPG값 1인 행렬을 맞춰야 하므로\n",
        "outputs = layers.Dense(1)(h)\n",
        "\n",
        "# 행렬 정의 완료. \n",
        "model = keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaKrnBde0giH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0egtq9xxvycm",
        "outputId": "0e98599f-6f5d-481a-b98a-ff00d4b3277e"
      },
      "source": [
        "model.compile(loss = 'mse', optimizer = tf.keras.optimizers.RMSprop(0.001))\n",
        "\n",
        "# summary 통해, 시각화 시도\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 6)]               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "4bXHr_8c0wt_",
        "outputId": "247b9245-99c7-4a6f-caab-3bae487aa38e"
      },
      "source": [
        "#레이어 별로, input과 output 보기\n",
        "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes = True)\n",
        "\n",
        "# input과 output 사이의 히든레이어를 추가하고자 한다(현재는 1개)\n",
        "# h가, 다음 레이어의 input으로 들어가야 함.\n",
        "inputs = keras.Input(shape=(normed_train_data.shape[1],))\n",
        "h = layers.Dense(64)(inputs)\n",
        "h = layers.Dense(32)(h)\n",
        "outputs = layers.Dense(1)(h)\n",
        "\n",
        "model = keras.Model(inputs = inputs, outputs = outputs)\n",
        "#결과, 레이어가 1개 증가\n",
        "model.compile(loss = 'mse', optimizer = tf.keras.optimizers.RMSprop(0.001))\n",
        "model.summary()\n",
        "\"\"\"컴파일은, input 데이터를, y = x*W+b 하는 것\n",
        "이 떄, W와 b(bias)를 점차 변화시켜가며, 행렬값을, y를 실제 정답과 일치하도록 해야 함\n",
        "이 '오차를 줄여가는 과정'을 나아가는 것이 ML\n",
        "차이를 표현하는 방법 중, loss = 'mse'를 이용 & optimizer : 오차가 생겼을 떄, b를 어떻게 \n",
        "변경해갈 것인가? RMSprop을 이용\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "y = W*x+b의 W와 b는 현재 임의로 지정된 값. \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 6)]               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,561\n",
            "Trainable params: 2,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny = W*x+b의 W와 b는 현재 임의로 지정된 값. \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jAazYVkr5Dm5",
        "outputId": "63c2fbca-41df-44c8-947b-ed66b785d11a"
      },
      "source": [
        "\"\"\"\n",
        "점차 학습시켜가며 똑똑하게 하자. 5개의 모델만을 test(with predict)\n",
        "\"\"\"\n",
        "example_batch = normed_train_data[:5]\n",
        "example_result = model.predict(example_batch) #부정확한 값. 이제, 학습시킨다\n",
        "example_result\n",
        "\n",
        "# 이 모델을 훈련. fit 통해, 학습시켜간다(행렬값이바뀌며, y가 실제값에 가까워짐)\n",
        "#fit안에, x값(인풋데이터), 정답데이터(y), epoch삽입\n",
        "\"\"\"\n",
        "epoch: dataset 전체(318row)를, 각 한 번 학습하면 1. 이를 총 얼마나 학습할 것인가?\n",
        "트레이닝 하면, loss는 감소할 것. but 과적합의 문제: 무조건 똑똑해지면 안됨.\n",
        "어느 정도의 수준값까지만 똑똑해져야 함(validation loss). 학습에 쓰이지 않은 data.\n",
        "이 loss값을 보고, 과적합/아직 학습가능 여부 판단\n",
        "\"\"\"\n",
        "\n",
        "EPOCHS = 200\n",
        "history = model.fit(normed_train_data, train_labels, epochs = EPOCHS,\n",
        "                    validation_split = 0.2)\n",
        "\n",
        "\"\"\"\n",
        "오차 loss(트레이닝 로스), validation loss 전부 감소 중\n",
        "만일 이 EPCOH를 100으로 하면, 이 역시 더 작아지는데, 어느 순간부터 급격한 감소는 사라짐.\n",
        "이것을 가능케 하는 건 '케라스'로, VALIDATION LOSS를 자동으로 EARLY STOPPING통해\n",
        "트레이닝 멈추는 조건을 찾음\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 25.9118 - val_loss: 26.8348\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.7577 - val_loss: 19.2320\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.6239 - val_loss: 15.7348\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.7632 - val_loss: 14.4052\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.0814 - val_loss: 13.6559\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8838 - val_loss: 13.3050\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9717 - val_loss: 12.8486\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.7130 - val_loss: 13.7741\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0731 - val_loss: 12.5443\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8265 - val_loss: 13.0230\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5837 - val_loss: 12.6821\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6399 - val_loss: 12.2814\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9070 - val_loss: 12.0243\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8852 - val_loss: 12.1664\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6410 - val_loss: 12.3896\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.4747 - val_loss: 13.1980\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3530 - val_loss: 12.7149\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7710 - val_loss: 15.2310\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4107 - val_loss: 12.9322\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6465 - val_loss: 11.9082\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5466 - val_loss: 13.2311\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.6783 - val_loss: 12.2480\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3818 - val_loss: 13.6379\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6112 - val_loss: 11.8659\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.8363 - val_loss: 12.2438\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6748 - val_loss: 11.8072\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4488 - val_loss: 12.3082\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6703 - val_loss: 12.6831\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7470 - val_loss: 12.2326\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6797 - val_loss: 12.9026\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3548 - val_loss: 12.3814\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2776 - val_loss: 14.1352\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1121 - val_loss: 12.1129\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.4522 - val_loss: 11.9401\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7060 - val_loss: 12.0041\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7060 - val_loss: 11.7730\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9495 - val_loss: 12.0568\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3822 - val_loss: 11.6302\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.7551 - val_loss: 12.2420\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4828 - val_loss: 12.9168\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9241 - val_loss: 12.0594\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.4167 - val_loss: 12.0411\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7673 - val_loss: 12.2130\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0102 - val_loss: 11.9736\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5845 - val_loss: 12.0554\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6229 - val_loss: 12.0710\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6458 - val_loss: 12.1812\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.7038 - val_loss: 12.9487\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2393 - val_loss: 11.6520\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4467 - val_loss: 12.5239\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.9164 - val_loss: 11.6219\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9332 - val_loss: 12.2241\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5507 - val_loss: 11.9786\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6474 - val_loss: 12.3959\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5402 - val_loss: 12.2858\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5425 - val_loss: 12.1115\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4004 - val_loss: 12.3670\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7172 - val_loss: 12.3193\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0008 - val_loss: 12.1522\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.5218 - val_loss: 11.7685\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5209 - val_loss: 12.1237\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.3095 - val_loss: 12.2636\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4322 - val_loss: 15.0300\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7981 - val_loss: 11.8478\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.4906 - val_loss: 13.3329\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.6433 - val_loss: 12.0000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6712 - val_loss: 12.5657\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6756 - val_loss: 12.8481\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3641 - val_loss: 11.8328\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8487 - val_loss: 12.0309\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.2654 - val_loss: 11.9314\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9114 - val_loss: 12.0340\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2888 - val_loss: 13.4683\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8777 - val_loss: 12.0701\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6364 - val_loss: 12.6567\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5158 - val_loss: 12.7341\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7347 - val_loss: 12.7097\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5104 - val_loss: 12.1110\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5651 - val_loss: 12.0956\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3166 - val_loss: 12.4093\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7622 - val_loss: 13.1014\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6976 - val_loss: 13.4102\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.8541 - val_loss: 12.3856\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3728 - val_loss: 12.2460\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5228 - val_loss: 11.8117\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3682 - val_loss: 12.9615\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.7569 - val_loss: 12.0423\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.2014 - val_loss: 11.7523\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2450 - val_loss: 12.1451\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6023 - val_loss: 11.9801\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7485 - val_loss: 12.0804\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6672 - val_loss: 12.3705\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5667 - val_loss: 12.2243\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5694 - val_loss: 11.8624\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5123 - val_loss: 12.2958\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0443 - val_loss: 11.6149\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4004 - val_loss: 12.1952\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6105 - val_loss: 12.0897\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4086 - val_loss: 11.9809\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1321 - val_loss: 12.4002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n오차 loss(트레이닝 로스), validation loss 전부 감소 중\\n만일 이 EPCOH를 100으로 하면, 이 역시 더 작아지는데, 어느 순간부터 급격한 감소는 사라짐.\\n이것을 가능케 하는 건 '케라스'로, VALIDATION LOSS를 자동으로 EARLY STOPPING통해\\n트레이닝 멈추는 조건을 찾음\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoQEWTZeFzDv",
        "outputId": "c3ae7642-242a-452e-a941-298006ae005a"
      },
      "source": [
        "\"\"\"\n",
        "PATIENCE=10은, VALIDATION LOSS가 10번 이상 줄지 않으면, 학습을 그만시킨단 뜻\n",
        "\"\"\"\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "model.fit(normed_train_data, train_labels, epochs = EPOCHS, validation_split = 0.2,\n",
        "          callbacks = [early_stop])\n",
        "# EPOCH를 아무리 늘려도, 조건에 따라 학습이 멈춤"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 12.5078 - val_loss: 12.1389\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3083 - val_loss: 11.9249\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5814 - val_loss: 12.2908\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6611 - val_loss: 12.1470\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5498 - val_loss: 12.2798\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6479 - val_loss: 12.4106\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.9638 - val_loss: 12.4745\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.8767 - val_loss: 12.2747\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.8034 - val_loss: 11.8065\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5438 - val_loss: 12.4701\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5480 - val_loss: 11.8227\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2916 - val_loss: 11.6576\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6852 - val_loss: 11.6665\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5152 - val_loss: 12.5712\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4558 - val_loss: 12.0630\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.6418 - val_loss: 11.9791\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3809 - val_loss: 11.7270\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5087 - val_loss: 12.5600\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4876 - val_loss: 11.8555\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.3185 - val_loss: 12.2244\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.2311 - val_loss: 12.1442\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2727 - val_loss: 12.3182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8da3e697d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDYLBWj3HfYH",
        "outputId": "cefd5567-b93b-4900-f19d-1657dba1d963"
      },
      "source": [
        "\"\"\"\n",
        "이제, 평가를 하고자함. 그 결과, 맨 초기의 약 500에서 10.91까지 감소\n",
        "\"\"\"\n",
        "loss = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"테스트 세트의 평균 절대오차: {:5.2f} MPG\".format(loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 10.9052\n",
            "테스트 세트의 평균 절대오차: 10.91 MPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "iIMetT6oH1cu",
        "outputId": "a7648771-7d06-4a3b-d4e3-3a43dc23fb56"
      },
      "source": [
        "\"\"\"\n",
        "실제 값 예측 법: predict로\n",
        "\"\"\"\n",
        "test_prediction= model.predict(normed_test_data).flatten()\n",
        "\n",
        "#실제값과 예측값을 비교.\n",
        "plt.scatter(test_labels, test_prediction)\n",
        "plt.xlabel('TRUE Values [MPG]')\n",
        "plt.ylabel('Prediction [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0, plt.xlim()[1]])\n",
        "plt.ylim([0, plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}